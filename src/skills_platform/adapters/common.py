from __future__ import annotations

import json
from pathlib import Path

from ..models import SkillRecord


def ensure_output_dirs(base: Path) -> dict[str, Path]:
    dirs = {
        "base": base,
        "rules": base / "rules",
        "config": base / "config",
        "install": base / "install",
    }
    for path in dirs.values():
        path.mkdir(parents=True, exist_ok=True)
    return dirs


def write_shared_mcp_config(config_dir: Path, target: str) -> Path:
    payload = {
        "target": target,
        "mcpServers": {
            "skills-platform": {
                "command": "python3",
                "args": ["-m", "skills_platform.mcp_server", "--root", "skills"],
            }
        },
        "fallbackCli": {
            "command": "python3",
            "argsPrefix": ["-m", "skills_platform"],
        },
    }
    path = config_dir / "mcp.json"
    path.write_text(json.dumps(payload, indent=2) + "\n", encoding="utf-8")
    return path


def write_install_readme(install_dir: Path, target: str) -> Path:
    text = f"""# {target} install notes

This directory is generated by `skills_platform` for the `{target}` target.

## Recommended wiring

1. Copy or symlink files from `rules/` into the tool's rules/instructions location.
2. Register the MCP server using `config/mcp.json` (preferred).
3. If MCP is unavailable, call the CLI fallback:
   - `python3 -m skills_platform list --root skills`
   - `python3 -m skills_platform render --root skills --target {target} --output dist`
4. For action-capable skills, use:
   - `python3 -m skills_platform run <skill-id> --root skills`
"""
    path = install_dir / "README.md"
    path.write_text(text, encoding="utf-8")
    return path


def render_rule_markdown(target: str, skill: SkillRecord) -> str:
    openai_prompt = (
        skill.tool_overrides.get("openai", {})
        .get("interface", {})
        .get("default_prompt")
    )
    lines = [
        f"# {skill.title}",
        "",
        f"- `id`: `{skill.id}`",
        f"- `kind`: `{skill.kind}`",
        f"- `target`: `{target}`",
        f"- `summary`: {skill.summary}",
        "",
        "## Trigger",
        skill.frontmatter.get("description", "Use this skill when the trigger matches."),
        "",
        "## Preferred Execution",
        f"- MCP: `skills.run` with `skill_id={skill.id}`",
        f"- CLI fallback: `python3 -m skills_platform run {skill.id} --root skills`",
        f"- Local shorthand (if wrapper installed): `skills run {skill.id}`",
        "",
        "## Context Notes",
        f"- Source: `{skill.skill_md_path}`",
    ]
    if openai_prompt:
        lines.extend(["", "## Existing OpenAI Prompt", str(openai_prompt)])
    return "\n".join(lines) + "\n"

